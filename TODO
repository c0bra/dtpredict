TODO list for Perl module DateTime::Even::Predict

2/8/2009
* [NOTE] - I may have found a solution to the clustering problem. The S-means algorithm starts with an initial
  value for k (default 1) and then adds and removes clusters as needed. It relies on a user-defined
  threshold to determine whether a data point should be added to a cluster or put into a new cluster
  and if I use to standard deviation in the distances of each data point from the one before it then
  it seems to work perfectly in situations where data should not be clustered, i.e. given
  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] as the data points it will provide 10 clusters. If we add "12" onto
  the data list it will provide 11 clusters.
  - [NOTE] - However I just tried adding "15" instead of 12 onto the list and it creates 6 clusters
    rather than 11, essentially splitting the data in half. This might not be what we want, but it
    could be as the only thing we'll be using clustering for currently is finding the initial search point
    to look for date predictions from. If it gives a proper distance to use to find that search point then
    it could be OK.
* [IDEA] - We might want to add the capability to use multiple search points. For situations where we are
  clustering it's possible that the next date could go in the most recent cluster, or it could go in a
  new cluster. Searching from both the most recent date in the most recent cluster and the new cluster
  start point would be a good idea.
  - [IDEA] - We could also measure the average and standard deviation in the number of elements per cluster
    to determine if it should go in the most recent cluster or a new one.
  

2/5/2009
* [NOTE] - Both the "jump" method and silhouette testing have the same problem when it comes to identifying
  the proper number of clusters: neither can determine whether clustering is appropriate or not. Specifically
  the "jump" method will always show clustering with "1" as the number of clusters having the best distortion.
  And the silhouette method cannot be used to test with just 1 cluster as it has to have other centroids to
  compare against.
  - [IDEA] - What if we did a reverse test starting with a number of clusters equal to the number of data
    elements and go backwards? If the fit remains good or gets better going towards the maximum then maybe
    clustering is inappropriate? OR perhaps it will ALWAYS get better going towards the maximum.
  - [IDEA] - Maybe we could count back from the maximum number of clusters a number of steps equal to the
    square root of the maximum number of clusters, rounded up (so 4 for 10 clusters, 23 for 500 clusters)
    and use moving averages on the silhouette average dissimilarity to see if there is a downwards trend. Then
    use the same number of steps to check upwards from 2 clusters. If there is a number of clusters in the
    bottom section that has a greater average dissimilarity than the one with the max avg dissimilarity in the
    top section, then the clustering operation needs to be fully done. However if there is no good clustering
    in the bottom section and the avg dissimilarities trend downwards from the max number of clusters, then
    clustering is probably not a good fit and we can skip it. This is all assumptions but I haven't found a
    test case so far that disproves this, although admittedly I have only tested a handful of data sets.
    - Problem: clustering takes (possibly) exponentially longer to cluster as k increases.
* [NOTE] - So far the silhouette method seems about 10% faster in my simple benchmarking, which might not
  be the most accurate metric but it's probably close enough.

2/4/2009
* [IDEA] - It may be possible to dynamically discover which date-parts to use for predictions by measuring
  ALL of them (i.e. get their stdev and variance) and see which ones have the most importance statistically
  (lowest stdev, I believe) and then scale the weight of each bucket to each other. So the most important
  bucket gains a weight of 1, and each bucket scales to that one based on the size of its standard deviation.
    - One problem with this is larger date-parts (i.e. years or epoch second intervals) will have larger
      standard deviations than, say "day of week". Perhaps the stdev can be scaled to the average size of
      the items in the set. OR perhaps there's already an established way of normalizing stdevs to a scale
      of 0 to 1.
      - It looks like this is called The Coefficient of Variation: http://en.wikipedia.org/wiki/Coefficient_of_variation
      	"The coefficient of variation is useful because the standard deviation of data must always be understood in the
      	context of the mean of the data. The coefficient of variation is a dimensionless number. So when comparing
      	between data sets with different units or widely different means, one should use the coefficient of
      	variation for comparison instead of the standard deviation."

2/2/2009
* [IDEA] It would be be cool if you could pass your own buckets in with a certain type, so you could, say,
  look for recurrence based on intervals of 6 seconds, or 18 days, whatever.
* We need to be able to handle recording more than one interval per diff. If the dates are all offset from
  each other by 1 day 6 hours (May 1, 3:00; May 2, 6:00), we can't be predicting a new date that's
  exactly 1 day after the most recent one.
    ^ The best way to do this is probably to record intervals as epoch seconds, so everything is taken
      into account. Maybe record epoch seconds in addition to whole regular intervals like days & hours.

2/1/2009
* Add kls to Predict::new(), and then allow predict() to override them or add news ones (??)
* add_date() and add_dates() needs to properly validate dates passed in

1/27/2009
* Profile.pm needs to check bucket names that get passed in to see if they actually exist. Right now
  it tries to clone them and dies ungracefully.

12/22/2009
* Can we combine the interval and distinct buckets into one full bucket list? The names should mean there's no
  collisions (just confusion, maybe too much) and the 'type' identifier says how to use it. Probably not a
  good idea.
* train() needs to reset the bucket values each time it's called; right now they'll just increment endlessly
  -- This should be done but I'm not 100% sure.

12/18/2009
* Is there a way to use import() outside of a BEGIN block so that export tags can be imported?
* Change new() and predict() so options can be globally set in the object and overridden in
  each call to predict().
* We could create a bucket for is_weekend_day and create a custom callback for the accessor.
  We'd have to do duration differently, though.

12/17/2009
* Finish writing up pod so module can be alpha-released on CPAN
* Right now we are trimming off any date-part that is smaller than the smallest bucket we
  have turned on. We need to make it so this is done in the comparisons, rather than
  actually modifying dates we are given. OR MAYBE NOT, because of truncate()?

12/16/2009
* Due to possible DoS attack that can be done through very large duration operations (thousands
  of years in the future, etc), we'll need to add some sort of protection, I think.

??/??/????
* Add a clustering() method so that clustering can be turned on or off whenever
